{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b5f6b3",
   "metadata": {},
   "source": [
    "This notebook builds a dimensional Data Lakehouse that integrates country level data from multiple sources to support historical analysis and aggregation. Data is extracted from a relational MySQL database,  MongoDB, and CSV files, then cleaned, standardized, and combined using  Spark. The project creates a couple dimension tables including country, city, language, date, and income group, along with a fact table that stores country indicators over time such as internet usage, health index, mobile subscriptions, and physician density. These tables are designed to support analytical queries that summarize trends by year, continent, and income group. The final output of the notebook is a  populated lakehouse schema and example queries that show how the data can be used for post hoc analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fed333a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import os\n",
    "import json\n",
    "import builtins\n",
    "import pymongo\n",
    "import certifi\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_date, date_format, year, quarter, month, dayofmonth, weekofyear,\n",
    "    lower, trim, regexp_replace, lit\n",
    ")\n",
    "\n",
    "mysql_args = {\n",
    "    \"host_name\": \"localhost\",\n",
    "    \"port\": \"3306\",\n",
    "    \"db_name\": \"world\",\n",
    "    \"conn_props\": {\n",
    "        \"user\": \"root\",\n",
    "        \"password\": \"Aryal123@\",##fake password\n",
    "        \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "}\n",
    "\n",
    "mongodb_args = {\n",
    "    \"cluster_location\": \"atlas\",\n",
    "    \"user_name\": \"snehaaryal58_db_user\",\n",
    "    \"password\": \"v30J4C6N3WXTHABr\",\n",
    "    \"cluster_name\": \"worldcluster\",\n",
    "    \"cluster_subnet\": \"hdrff8i\",\n",
    "    \"db_name\": \"world_side\",\n",
    "    \"collection\": \"\",\n",
    "    \"null_column_threshold\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bab7f42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|default  |\n",
      "|world_dlh|\n",
      "+---------+\n",
      "\n",
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|         |stg_city    |true       |\n",
      "|         |stg_country |true       |\n",
      "|         |stg_income  |true       |\n",
      "|         |stg_language|true       |\n",
      "+---------+------------+-----------+\n",
      "\n",
      "+----+----------------------------------------------------+-------------+\n",
      "|Code|Name                                                |Continent    |\n",
      "+----+----------------------------------------------------+-------------+\n",
      "|ABW |Aruba                                               |North America|\n",
      "|AFG |Afghanistan                                         |Asia         |\n",
      "|AGO |Angola                                              |Africa       |\n",
      "|AIA |Anguilla                                            |North America|\n",
      "|ALB |Albania                                             |Europe       |\n",
      "+----+----------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_mongo_uri(args):\n",
    "    return f\"mongodb+srv://{args['user_name']}:{args['password']}@{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "\n",
    "threads = builtins.max(1, int(os.cpu_count() / 2))\n",
    "\n",
    "sparkConf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"World Lakehouse Local\")\n",
    "    .setMaster(f\"local[{threads}]\")\n",
    "    .set(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.33,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\")\n",
    "    .set(\"spark.mongodb.input.uri\", get_mongo_uri(mongodb_args))\n",
    "    .set(\"spark.mongodb.output.uri\", get_mongo_uri(mongodb_args))\n",
    "    .set(\"spark.sql.shuffle.partitions\", str(threads))\n",
    "    .set(\"spark.sql.warehouse.dir\", os.path.abspath(\"spark-warehouse\"))\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).enableHiveSupport().getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark.sql(\"DROP DATABASE IF EXISTS world_dlh CASCADE\")\n",
    "spark.sql(\"CREATE DATABASE world_dlh\")\n",
    "spark.sql(\"USE world_dlh\")\n",
    "\n",
    "def get_mysql_df(sql_query: str):\n",
    "    jdbc_url = f\"jdbc:mysql://{mysql_args['host_name']}:{mysql_args['port']}/{mysql_args['db_name']}\"\n",
    "    return (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", jdbc_url)\n",
    "        .option(\"driver\", mysql_args[\"conn_props\"][\"driver\"])\n",
    "        .option(\"user\", mysql_args[\"conn_props\"][\"user\"])\n",
    "        .option(\"password\", mysql_args[\"conn_props\"][\"password\"])\n",
    "        .option(\"query\", sql_query)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "spark.sql(\"SHOW DATABASES\").show(200, truncate=False)\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "df_test = get_mysql_df(\"SELECT Code, Name, Continent FROM country LIMIT 5\")\n",
    "df_test.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a735ea2",
   "metadata": {},
   "source": [
    "The dim_country table is built from the MySQL country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b26ec8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|world_dlh|dim_country |false      |\n",
      "|         |stg_city    |true       |\n",
      "|         |stg_country |true       |\n",
      "|         |stg_income  |true       |\n",
      "|         |stg_language|true       |\n",
      "+---------+------------+-----------+\n",
      "\n",
      "+-----------+------------+----------------------------------------------------+-------------+--------------------------+-------------------------+------------+----------+----------+---------------+---------+---------+---------------------------------------------+---------------------------------------------+------------------------------------------------------------+---------------+-------------+\n",
      "|country_key|country_code|country_name                                        |continent    |region                    |region_norm              |surface_area|indep_year|population|life_expectancy|gnp      |gnp_old  |local_name                                   |government_form                              |head_of_state                                               |capital_city_id|country_code2|\n",
      "+-----------+------------+----------------------------------------------------+-------------+--------------------------+-------------------------+------------+----------+----------+---------------+---------+---------+---------------------------------------------+---------------------------------------------+------------------------------------------------------------+---------------+-------------+\n",
      "|1          |ABW         |Aruba                                               |North America|Caribbean                 |caribbean                |193.00      |NULL      |103000    |78.4           |828.00   |793.00   |Aruba                                        |Nonmetropolitan Territory of The Netherlands |Beatrix                                                     |129            |AW           |\n",
      "|2          |AFG         |Afghanistan                                         |Asia         |Southern and Central Asia |southern and central asia|652090.00   |1919      |22720000  |45.9           |5976.00  |NULL     |Afganistan/Afqanestan                        |Islamic Emirate                              |Mohammad Omar                                               |1              |AF           |\n",
      "|3          |AGO         |Angola                                              |Africa       |Central Africa            |central africa           |1246700.00  |1975      |12878000  |38.3           |6648.00  |7984.00  |Angola                                       |Republic                                     |José Eduardo dos Santos                                     |56             |AO           |\n",
      "|4          |AIA         |Anguilla                                            |North America|Caribbean                 |caribbean                |96.00       |NULL      |8000      |76.1           |63.20    |NULL     |Anguilla                                     |Dependent Territory of the UK                |Elisabeth II                                                |62             |AI           |\n",
      "|5          |ALB         |Albania                                             |Europe       |Southern Europe           |southern europe          |28748.00    |1912      |3401200   |71.6           |3205.00  |2500.00  |Shqipëria                                    |Republic                                     |Rexhep Mejdani                                              |34             |AL           |\n",
      "|6          |AND         |Andorra                                             |Europe       |Southern Europe           |southern europe          |468.00      |1278      |78000     |83.5           |1630.00  |NULL     |Andorra                                      |Parliamentary Coprincipality                 |                                                            |55             |AD           |\n",
      "|7          |ANT         |Netherlands Antilles                                |North America|Caribbean                 |caribbean                |800.00      |NULL      |217000    |74.7           |1941.00  |NULL     |Nederlandse Antillen                         |Nonmetropolitan Territory of The Netherlands |Beatrix                                                     |33             |AN           |\n",
      "|8          |ARE         |United Arab Emirates                                |Asia         |Middle East               |middle east              |83600.00    |1971      |2441000   |74.1           |37966.00 |36846.00 |Al-Imarat al-´Arabiya al-Muttahida           |Emirate Federation                           |Zayid bin Sultan al-Nahayan                                 |65             |AE           |\n",
      "|9          |ARG         |Argentina                                           |South America|South America             |south america            |2780400.00  |1816      |37032000  |75.1           |340238.00|323310.00|Argentina                                    |Federal Republic                             |Fernando de la Rúa                                          |69             |AR           |\n",
      "|10         |ARM         |Armenia                                             |Asia         |Middle East               |middle east              |29800.00    |1991      |3520000   |66.4           |1813.00  |1627.00  |Hajastan                                     |Republic                                     |Robert Kotšarjan                                            |126            |AM           |\n",
      "+-----------+------------+----------------------------------------------------+-------------+--------------------------+-------------------------+------------+----------+----------+---------------+---------+---------+---------------------------------------------+---------------------------------------------+------------------------------------------------------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_country = get_mysql_df(\"\"\"\n",
    "SELECT\n",
    "  Code AS country_code,\n",
    "  Name AS country_name,\n",
    "  Continent AS continent,\n",
    "  Region AS region,\n",
    "  SurfaceArea AS surface_area,\n",
    "  IndepYear AS indep_year,\n",
    "  Population AS population,\n",
    "  LifeExpectancy AS life_expectancy,\n",
    "  GNP AS gnp,\n",
    "  GNPOld AS gnp_old,\n",
    "  LocalName AS local_name,\n",
    "  GovernmentForm AS government_form,\n",
    "  HeadOfState AS head_of_state,\n",
    "  Capital AS capital_city_id,\n",
    "  Code2 AS country_code2\n",
    "FROM country\n",
    "\"\"\")\n",
    "\n",
    "df_country = df_country.withColumn(\"region_norm\", lower(trim(regexp_replace(col(\"region\"), r\"\\s+\", \" \"))))\n",
    "df_country.createOrReplaceTempView(\"stg_country\")\n",
    "\n",
    "df_dim_country = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER (ORDER BY country_code) AS country_key,\n",
    "  country_code,\n",
    "  country_name,\n",
    "  continent,\n",
    "  region,\n",
    "  region_norm,\n",
    "  surface_area,\n",
    "  indep_year,\n",
    "  population,\n",
    "  life_expectancy,\n",
    "  gnp,\n",
    "  gnp_old,\n",
    "  local_name,\n",
    "  government_form,\n",
    "  head_of_state,\n",
    "  capital_city_id,\n",
    "  country_code2\n",
    "FROM stg_country\n",
    "\"\"\")\n",
    "\n",
    "df_dim_country.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"dim_country\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM dim_country ORDER BY country_key LIMIT 10\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf3195",
   "metadata": {},
   "source": [
    "The dim_city table is sourced from the MySQL city table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b115c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|world_dlh|dim_city    |false      |\n",
      "|world_dlh|dim_country |false      |\n",
      "|         |stg_city    |true       |\n",
      "|         |stg_country |true       |\n",
      "|         |stg_income  |true       |\n",
      "|         |stg_language|true       |\n",
      "+---------+------------+-----------+\n",
      "\n",
      "+--------+-------+-----------------------------------+------------+--------------------+---------------+\n",
      "|city_key|city_id|city_name                          |country_code|district            |city_population|\n",
      "+--------+-------+-----------------------------------+------------+--------------------+---------------+\n",
      "|1       |1      |Kabul                              |AFG         |Kabol               |1780000        |\n",
      "|2       |2      |Qandahar                           |AFG         |Qandahar            |237500         |\n",
      "|3       |3      |Herat                              |AFG         |Herat               |186800         |\n",
      "|4       |4      |Mazar-e-Sharif                     |AFG         |Balkh               |127800         |\n",
      "|5       |5      |Amsterdam                          |NLD         |Noord-Holland       |731200         |\n",
      "|6       |6      |Rotterdam                          |NLD         |Zuid-Holland        |593321         |\n",
      "|7       |7      |Haag                               |NLD         |Zuid-Holland        |440900         |\n",
      "|8       |8      |Utrecht                            |NLD         |Utrecht             |234323         |\n",
      "|9       |9      |Eindhoven                          |NLD         |Noord-Brabant       |201843         |\n",
      "|10      |10     |Tilburg                            |NLD         |Noord-Brabant       |193238         |\n",
      "+--------+-------+-----------------------------------+------------+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city = get_mysql_df(\"\"\"\n",
    "SELECT\n",
    "  ID AS city_id,\n",
    "  Name AS city_name,\n",
    "  CountryCode AS country_code,\n",
    "  District AS district,\n",
    "  Population AS city_population\n",
    "FROM city\n",
    "\"\"\")\n",
    "\n",
    "df_city.createOrReplaceTempView(\"stg_city\")\n",
    "\n",
    "df_dim_city = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER (ORDER BY city_id) AS city_key,\n",
    "  city_id,\n",
    "  city_name,\n",
    "  country_code,\n",
    "  district,\n",
    "  city_population\n",
    "FROM stg_city\n",
    "\"\"\")\n",
    "\n",
    "df_dim_city.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"dim_city\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM dim_city ORDER BY city_key LIMIT 10\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233ba15",
   "metadata": {},
   "source": [
    "The dim_language table is from the countrylanguage table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea96075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|world_dlh|dim_city    |false      |\n",
      "|world_dlh|dim_country |false      |\n",
      "|world_dlh|dim_language|false      |\n",
      "|         |stg_city    |true       |\n",
      "|         |stg_country |true       |\n",
      "|         |stg_income  |true       |\n",
      "|         |stg_language|true       |\n",
      "+---------+------------+-----------+\n",
      "\n",
      "+------------+------------+------------------------------+-----------+------------+\n",
      "|language_key|country_code|language                      |is_official|language_pct|\n",
      "+------------+------------+------------------------------+-----------+------------+\n",
      "|1           |ABW         |Dutch                         |T          |5.3         |\n",
      "|2           |ABW         |English                       |F          |9.5         |\n",
      "|3           |ABW         |Papiamento                    |F          |76.7        |\n",
      "|4           |ABW         |Spanish                       |F          |7.4         |\n",
      "|5           |AFG         |Balochi                       |F          |0.9         |\n",
      "|6           |AFG         |Dari                          |T          |32.1        |\n",
      "|7           |AFG         |Pashto                        |T          |52.4        |\n",
      "|8           |AFG         |Turkmenian                    |F          |1.9         |\n",
      "|9           |AFG         |Uzbek                         |F          |8.8         |\n",
      "|10          |AGO         |Ambo                          |F          |2.4         |\n",
      "+------------+------------+------------------------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lang = get_mysql_df(\"\"\"\n",
    "SELECT\n",
    "  CountryCode AS country_code,\n",
    "  Language AS language,\n",
    "  IsOfficial AS is_official,\n",
    "  Percentage AS language_pct\n",
    "FROM countrylanguage\n",
    "\"\"\")\n",
    "\n",
    "df_lang = (\n",
    "    df_lang\n",
    "    .withColumn(\"is_official\", col(\"is_official\").cast(\"string\"))\n",
    "    .withColumn(\"language_pct\", col(\"language_pct\").cast(\"double\"))\n",
    "    .dropDuplicates([\"country_code\", \"language\"])\n",
    ")\n",
    "\n",
    "df_lang.createOrReplaceTempView(\"stg_language\")\n",
    "\n",
    "df_dim_language = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER (ORDER BY country_code, language) AS language_key,\n",
    "  country_code,\n",
    "  language,\n",
    "  is_official,\n",
    "  language_pct\n",
    "FROM stg_language\n",
    "\"\"\")\n",
    "\n",
    "df_dim_language.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"dim_language\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM dim_language ORDER BY language_key LIMIT 10\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd6256",
   "metadata": {},
   "source": [
    "The date dimension is generated using a continuous date sequence from 1990 to 2026 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a677278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|tableName   |isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|world_dlh|dim_city    |false      |\n",
      "|world_dlh|dim_country |false      |\n",
      "|world_dlh|dim_date    |false      |\n",
      "|world_dlh|dim_language|false      |\n",
      "|         |stg_city    |true       |\n",
      "|         |stg_country |true       |\n",
      "|         |stg_income  |true       |\n",
      "|         |stg_language|true       |\n",
      "+---------+------------+-----------+\n",
      "\n",
      "+----------+--------+----+-------+-----+----------+---+-----------+------------+\n",
      "|full_date |date_key|year|quarter|month|month_name|day|day_of_week|week_of_year|\n",
      "+----------+--------+----+-------+-----+----------+---+-----------+------------+\n",
      "|1990-01-01|19900101|1990|1      |1    |January   |1  |Mon        |1           |\n",
      "|1990-01-02|19900102|1990|1      |1    |January   |2  |Tue        |1           |\n",
      "|1990-01-03|19900103|1990|1      |1    |January   |3  |Wed        |1           |\n",
      "|1990-01-04|19900104|1990|1      |1    |January   |4  |Thu        |1           |\n",
      "|1990-01-05|19900105|1990|1      |1    |January   |5  |Fri        |1           |\n",
      "|1990-01-06|19900106|1990|1      |1    |January   |6  |Sat        |1           |\n",
      "|1990-01-07|19900107|1990|1      |1    |January   |7  |Sun        |1           |\n",
      "|1990-01-08|19900108|1990|1      |1    |January   |8  |Mon        |2           |\n",
      "|1990-01-09|19900109|1990|1      |1    |January   |9  |Tue        |2           |\n",
      "|1990-01-10|19900110|1990|1      |1    |January   |10 |Wed        |2           |\n",
      "+----------+--------+----+-------+-----+----------+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_date = \"1990-01-01\"\n",
    "end_date = \"2026-12-31\"\n",
    "\n",
    "df_dim_date = (\n",
    "    spark.sql(f\"SELECT explode(sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day)) AS full_date\")\n",
    "    .withColumn(\"date_key\", date_format(col(\"full_date\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"year\", year(col(\"full_date\")))\n",
    "    .withColumn(\"quarter\", quarter(col(\"full_date\")))\n",
    "    .withColumn(\"month\", month(col(\"full_date\")))\n",
    "    .withColumn(\"month_name\", date_format(col(\"full_date\"), \"MMMM\"))\n",
    "    .withColumn(\"day\", dayofmonth(col(\"full_date\")))\n",
    "    .withColumn(\"day_of_week\", date_format(col(\"full_date\"), \"E\"))\n",
    "    .withColumn(\"week_of_year\", weekofyear(col(\"full_date\")))\n",
    ")\n",
    "\n",
    "df_dim_date.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"dim_date\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM dim_date ORDER BY full_date LIMIT 10\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022dfae",
   "metadata": {},
   "source": [
    "The fact table captures country level indicators over time, including: Internet usage, Health index, Mobile subscriptions, Physician density\n",
    "Each record is linked to:\n",
    "country_key from dim_country\n",
    "date_key from dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bffa82eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------+-----------+\n",
      "|namespace|tableName              |isTemporary|\n",
      "+---------+-----------------------+-----------+\n",
      "|world_dlh|dim_city               |false      |\n",
      "|world_dlh|dim_country            |false      |\n",
      "|world_dlh|dim_date               |false      |\n",
      "|world_dlh|dim_language           |false      |\n",
      "|world_dlh|fact_country_indicators|false      |\n",
      "|         |stg_city               |true       |\n",
      "|         |stg_country            |true       |\n",
      "|         |stg_income             |true       |\n",
      "|         |stg_language           |true       |\n",
      "+---------+-----------------------+-----------+\n",
      "\n",
      "+--------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "|date_key|country_key|country_code|internet_pct|health_index|mobile_subs_per_100|physicians_per_1000|\n",
      "+--------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "|20000101|100        |IND         |0.5         |0.61        |3.0                |0.6                |\n",
      "|20000101|57         |DEU         |18.3        |0.91        |55.0               |3.4                |\n",
      "|20000101|38         |CAN         |51.3        |0.91        |27.4               |2.1                |\n",
      "|20000101|77         |GBR         |26.8        |0.9         |59.0               |2.0                |\n",
      "|20000101|73         |FRA         |14.3        |0.9         |51.6               |3.3                |\n",
      "|20000101|110        |JPN         |22.9        |0.93        |62.4               |2.0                |\n",
      "|20000101|224        |USA         |43.1        |0.89        |39.2               |2.7                |\n",
      "|20000101|42         |CHN         |1.8         |0.73        |6.7                |1.6                |\n",
      "|20000101|182        |RUS         |2.0         |0.78        |3.2                |4.3                |\n",
      "|20000101|31         |BRA         |5.3         |0.71        |13.9               |1.2                |\n",
      "+--------+-----------+------------+------------+------------+-------------------+-------------------+\n",
      "\n",
      "+--------+--------+---------+\n",
      "|min_year|max_year|row_count|\n",
      "+--------+--------+---------+\n",
      "|2000    |2000    |12       |\n",
      "+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mongo_client():\n",
    "    uri = f\"mongodb+srv://{mongodb_args['user_name']}:{mongodb_args['password']}@{mongodb_args['cluster_name']}.{mongodb_args['cluster_subnet']}.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    return pymongo.MongoClient(uri, tlsCAFile=certifi.where())\n",
    "\n",
    "json_path = os.path.abspath(\"data/country_indicators.json\")\n",
    "with open(json_path, \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "client = mongo_client()\n",
    "db = client[mongodb_args[\"db_name\"]]\n",
    "db.drop_collection(\"country_indicators\")\n",
    "db[\"country_indicators\"].insert_many(indicators if isinstance(indicators, list) else [indicators])\n",
    "client.close()\n",
    "\n",
    "mongodb_args[\"collection\"] = \"country_indicators\"\n",
    "\n",
    "df_indicators = (\n",
    "    spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"database\", mongodb_args[\"db_name\"])\n",
    "    .option(\"collection\", mongodb_args[\"collection\"])\n",
    "    .load()\n",
    "    .drop(\"_id\")\n",
    ")\n",
    "\n",
    "cols = set(df_indicators.columns)\n",
    "if \"Code\" in cols:\n",
    "    df_indicators2 = df_indicators.withColumnRenamed(\"Code\", \"country_code\")\n",
    "elif \"iso3\" in cols:\n",
    "    df_indicators2 = df_indicators.withColumnRenamed(\"iso3\", \"country_code\")\n",
    "elif \"country\" in cols:\n",
    "    df_indicators2 = df_indicators.withColumnRenamed(\"country\", \"country_code\")\n",
    "else:\n",
    "    df_indicators2 = df_indicators\n",
    "\n",
    "df_fact_stage = (\n",
    "    df_indicators2\n",
    "    .withColumn(\"as_of\", to_date(col(\"as_of\")))\n",
    "    .withColumn(\"date_key\", date_format(col(\"as_of\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"internet_pct\", col(\"internet_pct\").cast(\"double\"))\n",
    "    .withColumn(\"health_index\", col(\"health_index\").cast(\"double\"))\n",
    "    .withColumn(\"mobile_subs_per_100\", col(\"mobile_subs_per_100\").cast(\"double\"))\n",
    "    .withColumn(\"physicians_per_1000\", col(\"physicians_per_1000\").cast(\"double\"))\n",
    "    .dropDuplicates([\"country_code\", \"date_key\"])\n",
    ")\n",
    "\n",
    "df_country_keys = spark.table(\"dim_country\").select(\"country_key\", \"country_code\")\n",
    "\n",
    "df_fact_indicators = (\n",
    "    df_fact_stage\n",
    "    .join(df_country_keys, \"country_code\", \"left\")\n",
    "    .select(\n",
    "        col(\"date_key\"),\n",
    "        col(\"country_key\"),\n",
    "        col(\"country_code\"),\n",
    "        col(\"internet_pct\"),\n",
    "        col(\"health_index\"),\n",
    "        col(\"mobile_subs_per_100\"),\n",
    "        col(\"physicians_per_1000\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_fact_indicators.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"fact_country_indicators\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM fact_country_indicators LIMIT 10\").show(10, truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  MIN(d.year) AS min_year,\n",
    "  MAX(d.year) AS max_year,\n",
    "  COUNT(*) AS row_count\n",
    "FROM fact_country_indicators f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "\"\"\").show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e5946",
   "metadata": {},
   "source": [
    "This section loads income group data from a CSV file and builds an income dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe801e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------+-----------+\n",
      "|namespace|tableName              |isTemporary|\n",
      "+---------+-----------------------+-----------+\n",
      "|world_dlh|dim_city               |false      |\n",
      "|world_dlh|dim_country            |false      |\n",
      "|world_dlh|dim_date               |false      |\n",
      "|world_dlh|dim_income             |false      |\n",
      "|world_dlh|dim_language           |false      |\n",
      "|world_dlh|fact_country_indicators|false      |\n",
      "|         |stg_city               |true       |\n",
      "|         |stg_country            |true       |\n",
      "|         |stg_income             |true       |\n",
      "|         |stg_language           |true       |\n",
      "+---------+-----------------------+-----------+\n",
      "\n",
      "+----------+-------------------------+-------------------------+------------+\n",
      "|income_key|region                   |region_norm              |income_group|\n",
      "+----------+-------------------------+-------------------------+------------+\n",
      "|1         |Antarctica               |antarctica               |High        |\n",
      "|2         |Australia and New Zealand|australia and new zealand|High        |\n",
      "|3         |Caribbean                |caribbean                |Upper middle|\n",
      "|4         |Central America          |central america          |Upper middle|\n",
      "|5         |Eastern Africa           |eastern africa           |Lower middle|\n",
      "|6         |Eastern Asia             |eastern asia             |Upper middle|\n",
      "|7         |Eastern Europe           |eastern europe           |Upper middle|\n",
      "|8         |Melanesia                |melanesia                |Lower middle|\n",
      "|9         |Micronesia               |micronesia               |Lower middle|\n",
      "|10        |Middle Africa            |middle africa            |Lower middle|\n",
      "|11        |North America            |north america            |High        |\n",
      "|12        |Northern Africa          |northern africa          |Upper middle|\n",
      "|13        |Northern Europe          |northern europe          |High        |\n",
      "|14        |Polynesia                |polynesia                |Upper middle|\n",
      "|15        |South America            |south america            |Upper middle|\n",
      "|16        |Southeast Asia           |southeast asia           |Upper middle|\n",
      "|17        |Southern Africa          |southern africa          |Upper middle|\n",
      "|18        |Southern and Central Asia|southern and central asia|Lower middle|\n",
      "|19        |Southern Europe          |southern europe          |High        |\n",
      "|20        |Western Africa           |western africa           |Lower middle|\n",
      "|21        |Western Asia             |western asia             |Upper middle|\n",
      "|22        |Western Europe           |western europe           |High        |\n",
      "+----------+-------------------------+-------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.abspath(\"data/country_income.csv\")\n",
    "\n",
    "df_income_raw = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(csv_path)\n",
    ")\n",
    "\n",
    "df_income_raw = df_income_raw.toDF(*[c.strip().lower().replace(\" \", \"_\") for c in df_income_raw.columns])\n",
    "\n",
    "if \"incomegroup\" in df_income_raw.columns and \"income_group\" not in df_income_raw.columns:\n",
    "    df_income_raw = df_income_raw.withColumnRenamed(\"incomegroup\", \"income_group\")\n",
    "\n",
    "df_income2 = (\n",
    "    df_income_raw\n",
    "    .select(\"region\", \"income_group\")\n",
    "    .withColumn(\"region_norm\", lower(trim(regexp_replace(col(\"region\"), r\"\\s+\", \" \"))))\n",
    "    .dropna(subset=[\"region\", \"income_group\"])\n",
    "    .dropDuplicates([\"region_norm\", \"income_group\"])\n",
    ")\n",
    "\n",
    "df_income2.createOrReplaceTempView(\"stg_income\")\n",
    "\n",
    "df_dim_income = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER (ORDER BY region_norm, income_group) AS income_key,\n",
    "  region,\n",
    "  region_norm,\n",
    "  income_group\n",
    "FROM stg_income\n",
    "\"\"\")\n",
    "\n",
    "df_dim_income.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"dim_income\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)\n",
    "spark.sql(\"SELECT * FROM dim_income ORDER BY income_key LIMIT 50\").show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67be1d8",
   "metadata": {},
   "source": [
    "These queries show how the data can be used to find average internet usage over time by continent and by income group. The table list at the end confirms that all tables were created correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2f92044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------+\n",
      "|year|continent    |avg_internet_pct|\n",
      "+----+-------------+----------------+\n",
      "|2000|Africa       |5.4             |\n",
      "|2000|Asia         |8.4             |\n",
      "|2000|Europe       |15.35           |\n",
      "|2000|North America|33.17           |\n",
      "|2000|South America|5.3             |\n",
      "+----+-------------+----------------+\n",
      "\n",
      "+----+------------+----------------+\n",
      "|year|income_group|avg_internet_pct|\n",
      "+----+------------+----------------+\n",
      "|2000|High        |31.75           |\n",
      "|2000|Lower middle|0.5             |\n",
      "|2000|Upper middle|7.08            |\n",
      "+----+------------+----------------+\n",
      "\n",
      "+---------+-----------------------+-----------+\n",
      "|namespace|tableName              |isTemporary|\n",
      "+---------+-----------------------+-----------+\n",
      "|world_dlh|dim_city               |false      |\n",
      "|world_dlh|dim_country            |false      |\n",
      "|world_dlh|dim_date               |false      |\n",
      "|world_dlh|dim_income             |false      |\n",
      "|world_dlh|dim_language           |false      |\n",
      "|world_dlh|fact_country_indicators|false      |\n",
      "|         |stg_city               |true       |\n",
      "|         |stg_country            |true       |\n",
      "|         |stg_income             |true       |\n",
      "|         |stg_language           |true       |\n",
      "+---------+-----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  d.year,\n",
    "  c.continent,\n",
    "  ROUND(AVG(f.internet_pct), 2) AS avg_internet_pct\n",
    "FROM fact_country_indicators f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "JOIN dim_country c ON f.country_key = c.country_key\n",
    "GROUP BY d.year, c.continent\n",
    "ORDER BY d.year, c.continent\n",
    "\"\"\").show(200, truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  d.year,\n",
    "  i.income_group,\n",
    "  ROUND(AVG(f.internet_pct), 2) AS avg_internet_pct\n",
    "FROM fact_country_indicators f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "JOIN dim_country c ON f.country_key = c.country_key\n",
    "JOIN dim_income i ON c.region_norm = i.region_norm\n",
    "GROUP BY d.year, i.income_group\n",
    "ORDER BY d.year, i.income_group\n",
    "\"\"\").show(200, truncate=False)\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511e562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a2cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653cb93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pysparkenv)",
   "language": "python",
   "name": "pysparkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
